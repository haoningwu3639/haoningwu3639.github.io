<html>

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <style type="text/css">
    @font-face {
      font-family: 'Avenir Book';
      src: url("./fonts/Avenir_Book.ttf");
      /* File to be stored at your site */
    }

    body {
      font-family: "Times New Roman", "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
      font-weight: 200;
      font-size: 16px;
      margin-left: auto;
      margin-right: auto;
      width: 800px;
    }

    h1 {
      font-weight: 400;
    }

    h2 {
      font-weight: 400;
    }

    p {
      font-weight: 200;
      line-height: 1.4;
    }

    code {
      font-size: 0.8rem;
      margin: 0 0.2rem;
      padding: 0.5rem 0.8rem;
      white-space: nowrap;
      background: #efefef;
      border: 1px solid #d3d3d3;
      color: #000000;
      border-radius: 3px;
    }

    pre>code {
      display: block;
      white-space: pre;
      line-height: 1.5;
      padding: 0;
      margin: 0;
    }

    pre.prettyprint>code {
      border: none;
    }


    .container {
      display: flex;
      align-items: center;
      justify-content: center
    }

    .image {
      flex-basis: 40%
    }

    .text {
      padding-left: 20px;
      padding-right: 20px;
    }

    .disclaimerbox {
      background-color: #eee;
      border: 1px solid #eeeeee;
      border-radius: 10px;
      -moz-border-radius: 10px;
      -webkit-border-radius: 10px;
      padding: 20px;
    }

    video.header-vid {
      height: 140px;
      border: 1px solid black;
      border-radius: 10px;
      -moz-border-radius: 10px;
      -webkit-border-radius: 10px;
    }

    img.header-img {
      height: 140px;
      border: 1px solid black;
      border-radius: 10px;
      -moz-border-radius: 10px;
      -webkit-border-radius: 10px;
    }

    img.rounded {
      border: 0px solid #eeeeee;
      border-radius: 10px;
      -moz-border-radius: 10px;
      -webkit-border-radius: 10px;

    }

    a:link,
    a:visited {
      color: #1367a7;
      text-decoration: none;
    }

    a:hover {
      color: #208799;
    }

    td.dl-link {
      height: 160px;
      text-align: center;
      font-size: 22px;
    }

    .layered-paper-big {
      /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
      box-shadow:
        0px 0px 1px 1px rgba(0, 0, 0, 0.35),
        /* The top layer shadow */
        5px 5px 0 0px #fff,
        /* The second layer */
        5px 5px 1px 1px rgba(0, 0, 0, 0.35),
        /* The second layer shadow */
        10px 10px 0 0px #fff,
        /* The third layer */
        10px 10px 1px 1px rgba(0, 0, 0, 0.35),
        /* The third layer shadow */
        15px 15px 0 0px #fff,
        /* The fourth layer */
        15px 15px 1px 1px rgba(0, 0, 0, 0.35),
        /* The fourth layer shadow */
        20px 20px 0 0px #fff,
        /* The fifth layer */
        20px 20px 1px 1px rgba(0, 0, 0, 0.35),
        /* The fifth layer shadow */
        25px 25px 0 0px #fff,
        /* The fifth layer */
        25px 25px 1px 1px rgba(0, 0, 0, 0.35);
      /* The fifth layer shadow */
      margin-left: 10px;
      margin-right: 45px;
    }


    .layered-paper {
      /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
      box-shadow:
        0px 0px 1px 1px rgba(0, 0, 0, 0.35),
        /* The top layer shadow */
        5px 5px 0 0px #fff,
        /* The second layer */
        5px 5px 1px 1px rgba(0, 0, 0, 0.35),
        /* The second layer shadow */
        10px 10px 0 0px #fff,
        /* The third layer */
        10px 10px 1px 1px rgba(0, 0, 0, 0.35);
      /* The third layer shadow */
      margin-top: 5px;
      margin-left: 10px;
      margin-right: 30px;
      margin-bottom: 5px;
    }

    .vert-cent {
      position: relative;
      top: 50%;
      transform: translateY(-50%);
    }

    hr {
      border: 0;
      height: 1px;
      background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
    }
  </style>
  <link rel="icon"
    href="data:image/svg+xml, <svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ü©ª</text></svg>">
  <title>MRGen</title>
</head>

<body data-new-gr-c-s-check-loaded="14.1093.0" data-gr-ext-installed="">
  <center>
    <span
      style="font-size:36px; color:#4d4d4d; font-family: Varela Round,sans-serif; font-weight: 700; line-height: 65px;">MRGen</span><br>
    <span style="font-size:28px">Segmentation Data Engine for Underrepresented MRI Modalities</span><br><br>
  </center>

  <table align="center" width="800px">
    <tbody>
      <tr>
        <td align="center" width="130px">
          <center>
            <span style="font-size:20px"><a href="https://haoningwu3639.github.io/">Haoning
                Wu</a><sup>1,2*</sup></span>
          </center>
        </td>
        <td align="center" width="120px">
          <center>
            <span style="font-size:20px"><a href="https://zhaoziheng.github.io/">Ziheng Zhao</a><sup>1,2*</sup></span>
          </center>
        </td>
        <td align="center" width="110px">
          <center>
            <span style="font-size:20px"><a href="https://annzhanglion.github.io/">Ya
                Zhang</a><sup>1,2</sup></span>
          </center>
        </td>
        <td align="center" width="130px">
          <center>
            <span style="font-size:20px"><a href="https://cmic.sjtu.edu.cn/wangyanfeng/">Yanfeng Wang</a><sup>1,2 <img
                  class="round" style="width:20px" src="./resources/corresponding_fig.png"></sup></span>
          </center>
        </td>
        <td align="center" width="120px">
          <center>
            <span style="font-size:20px"><a href="https://weidixie.github.io/">Weidi Xie</a><sup>1,2 <img class="round"
                  style="width:20px" src="./resources/corresponding_fig.png"></sup></span>
          </center>
        </td>
      </tr>
    </tbody>
  </table><br>

  <table align="center" width="800px">
    <tbody>
      <tr>
        <td align="center" width="800px">
          <center>
            <span style="font-size:18px"><sup>1</sup>School of Artificial Intelligence, Shanghai Jiao Tong
              University</span>
          </center>
        </td>
      </tr>
    </tbody>
  </table>

  <table align="center" width="500px">
    <tbody>
      <tr>
        <td align="center" width="150px">
          <center>
            <span style="font-size:18px"><sup>2</sup>Shanghai Artificial Intelligence Laboratory</span>
          </center>
        </td>
      </tr>
    </tbody>
  </table>
  <br>

  <table align="center" width="800px">
    <tbody>
      <tr>
        <td align="center" width="800px">
          <center>
            <strong><span style="font-size:32px">ICCV 2025</span></strong>
          </center>
        </td>
      </tr>
    </tbody>
  </table>

  <table align="center" width="800px">
    <tbody>
      <tr>
        <td align="center" width="200px">
          <center>
            <br>
            <span style="font-size:20px">Code
              <a href="https://github.com/haoningwu3639/MRGen/"> [GitHub]</a>
            </span>
          </center>
        </td>

        <td align="center" width="200px">
          <center>
            <br>
            <span style="font-size:20px">
              Paper <a href="https://arxiv.org/abs/2412.04106/"> [arXiv]</a>
            </span>
          </center>
        </td>

        <td align="center" width="200px">
          <center>
            <br>
            <span style="font-size:20px">
              Cite <a href="./resources/bibtex.txt"> [BibTeX]</a>
            </span>
          </center>
        </td>
      </tr>
    </tbody>
  </table>
  <br>
  <hr>
  <br>
  <center>
    <img src="./resources/teaser.png" alt="alt text" style="width: 100%; object-fit: cover; max-width:100%;"></a>
  </center>
  <p style="text-align:justify; text-justify:inter-ideograph;">
    <left>
      <strong> Motivation and Overview. </strong>
      <strong><i>Left</i></strong>: The heterogeneity of MRI modalities challenges the generalization of segmentation models.
      Our proposed data engine, <strong>MRGen</strong>, overcomes this by controllably synthesizing training data for segmentation models.
      <strong><i>Right</i></strong>: (a) Prior generative models are restricted to 
      Previous generative models rely on <strong>mask-annotated data</strong> and are data augmentation for <strong>well-annotated modalities</strong>;
      (b) Image translation typically requires registered data pairs (dashed lines), and is limited to specific modality conversions;
      (c) <strong>MRGen</strong> enables controllable generation across diverse modalities, creating data for training segmentation models towards underrepresented modalities. 
      Distinct colors represent different modalities.
    </left>
  </p>

  <center>
    <h2> <strong> Abstract </strong> </h2>
  </center>
  <p style="text-align:justify; text-justify:inter-ideograph;">
  </p>
  <div class="container">
    <div class="text" width="400px">
      <p style="text-align:justify; text-justify:inter-ideograph;">
        <left>
          Training medical image segmentation models for rare yet clinically significant imaging modalities is challenging due to the scarcity of annotated data, 
          and manual mask annotations can be costly and labor-intensive to acquire. 
          This paper investigates <strong>leveraging generative models to synthesize training data, to train segmentation models for underrepresented modalities</strong>, 
          particularly on annotation-scarce MRI. 
          Concretely, our contributions are threefold: 
          (i) we introduce <strong>MRGen-DB</strong>, a large-scale radiology image-text dataset comprising extensive samples with rich metadata, including modality labels, attributes, regions, 
          and organs information, with a subset having pixelwise mask annotations; 
          (ii) we present <strong>MRGen</strong>, a diffusion-based data engine for controllable medical image synthesis, conditioned on text prompts and segmentation masks. 
          MRGen can generate realistic images for diverse MRI modalities lacking mask annotations, facilitating segmentation training in low-source domains; 
          (iii) extensive experiments across multiple modalities demonstrate that MRGen significantly improves segmentation performance on unannotated modalities by providing high-quality synthetic data. 
          We believe that our method bridges a critical gap in medical image analysis, extending segmentation capabilities to scenarios that are challenging to acquire manual annotations.
        </left>
      </p>
    </div>
  </div>

  <hr>

  <center>
    <h2> <strong> MRGen Architecture </strong> </h2>
  </center>
  <p><img class="center" src="./resources/architecture.png" width="750px"></p>
  <p>
    <left>
      <strong style="font-weight: 900"> Architecture Overview. </strong style="font-weight: 900">
      Developing our MRGen involves three key steps:
      (a) Train an autoencoder on various images from MRGen-DB dataset;
      (b) Train a text-guided generative model within the latent space, using image-text pairs across diverse modalities from MRGen-DB, 
      featuring <span style="color: #FF0000;">modality</span>, <span style="color: #7030A0;">attributes</span>,
      <span style="color: #92D050;">region</span>, and <span style="color: #00B0F0;">organs</span> information;
      (c) Train a mask condition controller jointly on image-text pairs with
      and without mask annotations, enabling controllable generation based on both text prompts and masks.
    </left>
  </p>
  <hr>

  <center>
    <h2> <strong> Results </strong> </h2>
  </center>
  <h3>
    <center>
      <strong> Quantitative Results </strong>
    </center>
  </h3>
  <center>
    <p><img class="center" src="./resources/quantitative_results_generation.png" width="450px"></p>
  </center>
  <p>
    <strong> Quantitative Results (FID) on Generation. </strong>
    Here, CM., MP., PS., LQ., and PR., denote CHAOS-MRI, MSD-Prostate, PanSeg, LiQA, and PROMISE12, respectively.
  </p>

  <center>
    <p><img class="center" src="./resources/quantitative_results_segmentation.png" width="780px"></p>
  </center>
  <p><strong> Quantitative Results (DSC score) on Segmentation. </strong>
    Here, Dsdenotes training with manually annotated source-domain data. 
    Results with the best and second best results are <strong>bolded</strong> and <span
    style="text-decoration: underline;">underlined</span>, respectively.
  <h3>
    <center>
      <strong> Qualitative Results </strong>
    </center>
  </h3>

  <p> <img class="center" src="./resources/qualitative_results_generation.png" width="800px"> </p>
  <p><strong> Qualitative Results of Controllable Generation. </strong>
    We present images from the source domain <span style="font-style: normal;">ùíü<sub><i>s</i></sub></span> and the
    target domain <span style="font-style: normal;">ùíü<sub><i>t</i></sub></span> for reference.
    Here, <span style="color: #FF0000;">liver</span>, <span style="color: #92D050;">right kidney</span>, 
    <span style="color: #00B0F0;">left kidney</span>, <span style="color: #FFFF00;">spleen</span>, <span style="color: #FF0000;">prostate</span>,
    and <span style="color: #FF0000;">pancreas</span>, are contoured with different colors.
  </p>

  <p><img class="center" src="./resources/qualitative_results_segmentation.png" width="800px"></p>
  <p><strong>Qualitative Results of Segmentation towards Unannotated Modalities.</strong>
    Significant imaging differences between source-domain (<span style="font-style: normal;">ùíü<sub><i>s</i></sub></span>) 
    and target-domain (<span style="font-style: normal;">ùíü<sub><i>t</i></sub></span>) make segmentation on 
    target domains (<span style="font-style: normal;">ùíü<sub><i>t</i></sub></span>) extremely challenging. 
    We visualize <span style="color: #FF0000;">liver</span>, <span style="color: #92D050;">right kidney</span>, <span
    style="color: #00B0F0;">left kidney</span>, and <span style="color: #FFFF00;">spleen</span> in the first two rows, 
    <span style="color: #FF0000;">prostate</span> in the third row, 
    and <span style="color: #FF0000;">pancreas</span> in the fourth row with distinct colors.
  </p>

  <hr>

  <center>
    <h2> <strong> Data Statistics </strong> </h2>
  </center>

  <p><img class="center" src="./resources/data_statistics_1.png" width="800px"></p>

  <p>
    <strong> Data Statistics of <i>Radiopaedia-MRI</i>. </strong>
    (a) Distribution of slice counts across various modalities in <i>Radiopaedia-MRI</i>;
    (b) Proportional distribution of slices across different regions in <i>Radiopaedia-MRI</i>.
  </p>

  <p><img class="center" src="./resources/data_statistics_2.png" width="800px"></p>
  <p>
    <strong> Details of Segmentation-annotated Datasets in MRGen-DB. </strong>
    Here, # Vol. represents the number of 3D Volumes, # Slc. denotes the number of 2D slices, and # Slc. w/ mask indicates the number of 2D slices with mask annotations.
  </p>

  <hr>

  <center>
    <h2> <strong> More Visualization </strong> </h2>
  </center>

  <p><img class="center" src="./resources/more_qualitative_results_generation.png" width="800px"></p>
  <p><strong> More Qualitative Results of Controllable Generation. </strong>
    We present images from source domains (<span style="font-style: normal;">ùíü<sub><i>s</i></sub></span>) 
    and target domains (<span style="font-style: normal;">ùíü<sub><i>t</i></sub></span>) for reference.
    Here, specific organs are contoured with colors: <span style="color: #FF0000;">prostate</span> in
    MSD-Prostate and PROMISE12 datasets, and <span style="color: #FF0000;">pancreas</span> in PanSeg dataset, and <span
      style="color: #FF0000;">liver</span> in LiQA and CHAOS-MRI datasets.
  </p>

  <p><img class="center" src="./resources/more_qualitative_results_segmentation.png" width="800px"></p>
  <p><strong> More Qualitative Results on Segmentation towards Unannotated Modalities. </strong>
    Significant imaging differences between source-domain (<span style="font-style: normal;">ùíü<sub><i>s</i></sub></span>), 
    and target-domain (<span style="font-style: normal;">ùíü<sub><i>t</i></sub></span>), 
    make segmentation on target domains (<span style="font-style: normal;">ùíü<sub><i>t</i></sub></span>) extremely challenging.
    Here, specific organs are highlighted with colors: <span style="color: #FF0000;">prostate</span> in
    MSD-Prostate and PROMISE12 datasets, and <span style="color: #FF0000;">pancreas</span> in PanSeg dataset, and <span
      style="color: #FF0000;">liver</span> in LiQA and CHAOS-MRI datasets.
  </p>

  <br>

  <p>
    <center>
      <strong>Welcome to check out our paper for more technical details and results!</strong>
    </center>
  </p>

  <hr>

  <center>
    <h2> <strong> Acknowledgements </strong> </h2>
  </center>
  <p>
    Based on a template by <a href="http://web.mit.edu/phillipi/">Phillip Isola</a> and <a
      href="http://richzhang.github.io/">Richard Zhang</a>.
  </p>
  <br>
  <br>


</body><grammarly-desktop-integration data-grammarly-shadow-root="true"></grammarly-desktop-integration>

</html>